{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from lxml import etree\n",
    "from lxml.html.clean import Cleaner\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open('datasets/golos_io_topics.xml', encoding='utf-8')\n",
    "data = file.read();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = Cleaner()\n",
    "cleaner.allow_tags = ['item', 'field']\n",
    "cleaner.remove_unknown_tags = False\n",
    "clean_data = cleaner.clean_html(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = codecs.open('datasets/golos_io_topics-res.xml', encoding='utf-8', mode='w+')\n",
    "fout.write(clean_data)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.fromstring(clean_data)\n",
    "items = tree.xpath(\"//field[@name='body']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list = [item.text for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "\n",
    "def convert_prefix2utags(mystem_prefix):\n",
    "    utags_dict = {'_A':       '_ADJ',\n",
    "                  '_ADV':     '_ADV',                                                                                                                                                                                                                                                                    \n",
    "                  '_ADVPRO':  '_ADV',                                                                                                                                                                                                                                                                    \n",
    "                  '_ANUM':    '_ADJ',                                                                                                                                                                                                                                                                 \n",
    "                  '_APRO':    '_DET',                                                                                                                                                                                                                                                                   \n",
    "                  '_COM':     '_ADJ',                                                                                                                                                                                                                                                                    \n",
    "                  '_CONJ':    '_SCONJ',                                                                                                                                                                                                                                                                  \n",
    "                  '_INTJ':    '_INTJ',                                                                                                                                                                                                                                                                   \n",
    "                  '_NONLEX':  '_X',                                                                                                                                                                                                                                                                      \n",
    "                  '_NUM':     '_NUM',                                                                                                                                                                                                                                                                    \n",
    "                  '_PART':    '_PART',                                                                                                                                                                                                                                                                   \n",
    "                  '_PR':      '_ADP',                                                                                                                                                                                                                                                                    \n",
    "                  '_S':       '_NOUN',                                                                                                                                                                                                                                                                   \n",
    "                  '_SPRO':    '_PRON',                                                                                                                                                                                                                                                                   \n",
    "                  '_UNKN':    '_X',                                                                                                                                                                                                                                                                      \n",
    "                  '_V':       '_VERB',\n",
    "                  '':        ''}\n",
    "    return utags_dict[mystem_prefix]\n",
    "\n",
    "def get_word_prefix(word):\n",
    "    lemmas = mystem.analyze(word)\n",
    "    prefix = \"\"\n",
    "    if (isinstance(lemmas, collections.Iterable)) and ('analysis' in lemmas[0]):\n",
    "        try:\n",
    "            prefix = \"_\"+(lemmas[0]['analysis'][0]['gr'].split(\"=\")[0].split(\",\")[0]) \n",
    "        except IndexError:\n",
    "            prefix = \"\"\n",
    "    return convert_prefix2utags(prefix)\n",
    "\n",
    "def lemmatize_words(word_list):\n",
    "    processed_word_list = []\n",
    "    for word in word_list:\n",
    "        word = mystem.lemmatize(word)[0]\n",
    "        word_w_prefix = word+get_word_prefix(word)\n",
    "        processed_word_list.append(word_w_prefix)\n",
    "    return processed_word_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['человек_NOUN']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatize_words([\"люди\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(word_list):\n",
    "        processed_word_list = []\n",
    "        for word in word_list:\n",
    "            word = word.lower() # in case they arenet all lower cased\n",
    "            if word not in stopwords.words(\"russian\") and len(word) > 2:\n",
    "                processed_word_list.append(word)\n",
    "        return processed_word_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = nltk.word_tokenize(seq_list[1200])\n",
    "test_clean = remove_stopwords(test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_doc(doc_text):\n",
    "    words_list = remove_stopwords(nltk.word_tokenize(doc_text))\n",
    "    lemmas_list = lemmatize_words(words_list)\n",
    "    return \" \".join(lemmas_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'самый_DET интересный_ADJ вопрос_NOUN который_DET задавать_VERB ученый_NOUN исследователь_NOUN старение_NOUN сам_DET принимать_VERB увеличение_NOUN продолжительность_NOUN жизнь_NOUN узнавать_VERB это_PRON большой_ADJ конференция_NOUN старение_NOUN долголетие_NOUN сразу_ADV видно_ADV современный_ADJ состояние_NOUN дело_NOUN наука_NOUN геропротектор_NOUN услышать_VERB довольно_ADV разный_ADJ ответ_NOUN метформин_NOUN аспирин_NOUN ибупрофный_ADJ витамин_NOUN литий_NOUN витамин_NOUN витамин_NOUN статин_NOUN рапамицин_NOUN далее_ADV многое_PRON оставаться_VERB непонятный_ADJ применение_NOUN какой_DET доза_NOUN учитывать_VERB индивидуальный_ADJ особенность_NOUN работать_VERB клинический_ADJ исследование_NOUN данна_NOUN комбинация_NOUN один_DET научный_ADJ статья_NOUN написать_VERB один_DET другой_DET выходить_VERB писать_VERB пропадать_VERB принимать_VERB другой_DET пожалуй_PART майкл_NOUN шнайдер_NOUN стенфорд_NOUN качественно_ADV исследовать_VERB рассматривать_VERB изменение_NOUN сотня_NOUN тысяча_NOUN показатель_NOUN свой_DET организм_NOUN сказать_VERB создавать_VERB целовать_VERB наука_NOUN здоровье_NOUN майкл_NOUN шнайдер_NOUN также_ADV сайт_NOUN лонжесити_NOUN человек_NOUN употреблять_VERB различный_ADJ препарат_NOUN делиться_VERB свой_DET впечатление_NOUN акцент_NOUN ноотроп_NOUN продление_NOUN жизнь_NOUN все_PRON это_PRON процесс_NOUN хватать_VERB организованность_NOUN собственно_ADV это_PRON заниматься_VERB прекрасный_ADJ план_NOUN шаг_NOUN личный_ADJ медицинский_ADJ кабинет_NOUN должный_ADJ результат_NOUN ваш_DET анализ_NOUN сдавать_VERB терапия_NOUN который_DET осуществлять_VERB самый_DET важно_ADV должный_ADJ результат_NOUN диагностика_NOUN старение_NOUN плюс_NOUN описание_NOUN интервенция_NOUN против_ADP старение_NOUN биомаркер_NOUN скорость_NOUN старение_NOUN далекий_ADJ совершенство_NOUN какой_DET скажем_ADV именно_PART нужно_ADV измерять_VERB тип_NOUN интерлейкин_NOUN с_NOUN белка_NOUN холестерин_NOUN скорость_NOUN распространение_NOUN пульсовый_ADJ волна_NOUN инсулино_NOUN фактор_NOUN рост_NOUN далее_ADV далеко_ADV совершать_VERB следующий_ADJ действие_NOUN собственный_ADJ данные_NOUN открывать_VERB все_PRON желать_VERB свой_DET фамилия_NOUN открывать_VERB все_PRON желать_VERB анонимно_ADV открывать_VERB медицинский_ADJ организация_NOUN никто_PRON открывать_VERB знать_VERB сам_DET лично_ADV выбирать_VERB первый_ADJ вариант_NOUN заинтересовывать_VERB кто-то_PRON все_PRON время_NOUN обсуждать_VERB процесс_NOUN старение_NOUN анализировать_VERB все_PRON шаг_NOUN достаточно_ADV вызывать_VERB лавинообразный_ADJ интерес_NOUN то_PART мочь_NOUN действовать_VERB терапия_NOUN против_ADP старение_NOUN менее_ADV следующий_ADJ шаг_NOUN шаг_NOUN организация_NOUN обсуждение_NOUN биомаркер_NOUN терапия_NOUN против_ADP старение_NOUN быть_VERB весть_NOUN абстрактный_ADJ разговор_NOUN результат_NOUN собственный_ADJ анализ_NOUN выбор_NOUN терапия_NOUN научный_ADJ совет_NOUN речь_NOUN идти_VERB существовать_VERB препарат_NOUN другой_DET назначение_NOUN тип_NOUN статин_NOUN шаг_NOUN подготовка_NOUN документ_NOUN клинический_ADJ исследование_NOUN шаг_NOUN краудфандинг_NOUN клинический_ADJ исследование_NOUN шаг_NOUN проведение_NOUN клинический_ADJ исследование_NOUN терапия_NOUN против_ADP старение_NOUN шаг_NOUN анализ_NOUN результат_NOUN организация_NOUN новый_ADJ исследование_NOUN шаг_NOUN краудфандинг_NOUN сбор_NOUN пожертвование_NOUN разработка_NOUN принципиально_ADV новый_ADJ вмешательство_NOUN тип_NOUN генный_ADJ терапия_NOUN шаг_NOUN социальный_ADJ сеть_NOUN собственный_ADJ медицинский_ADJ искусственный_ADJ интеллект_NOUN естественно_ADV рассказывать_VERB миллиард_NOUN деталь_NOUN это_PRON вопрос_NOUN человек_NOUN который_DET взяться_VERB организация_NOUN дорога_NOUN создавать_VERB самый_DET персональный_ADJ медицина_NOUN отмечать_VERB один_DET удерживать_VERB мелочный_ADJ желание_NOUN прикручивать_VERB сам_DET какой-нибудь_DET частный_ADJ сервис_NOUN что-нибудь_PRON лично_ADV запатентовывать_VERB платформа_NOUN должный_ADJ принадлежать_VERB все_PRON участник_NOUN проект_NOUN человек_NOUN голос_NOUN потребительский_ADJ кооператив_NOUN зарплата_NOUN тот_DET работать_VERB коварный_ADJ вопрос_NOUN находить_VERB деньги_NOUN первый_ADJ клинический_ADJ исследование_NOUN продолжать_VERB привлекать_VERB человек_NOUN например_ADV пока_ADV среди_ADP оказываться_VERB который_DET готовый_ADJ оплачивать_VERB исследование_NOUN ради_ADP один_DET человек_NOUN очень_ADV главный_ADJ смочь_VERB проводить_VERB один_DET клинический_ADJ исследование_NOUN понимать_VERB нужно_ADV принимать_VERB против_ADP старение_NOUN наш_DET задача_NOUN повышать_VERB качество_NOUN доступность_NOUN научный_ADJ дискуссия_NOUN скоро_ADV пример_NOUN показывать_VERB это_PRON происходить_VERB второй_ADJ коварный_ADJ вопрос_NOUN все_PRON своровать_VERB пожалуйста_PART пусть_PART человек_NOUN обгонять_VERB борьба_NOUN старение_NOUN википедия_NOUN переживать_VERB скопипастенок_NOUN цель_NOUN свободный_ADJ распространение_NOUN знание_NOUN кто-то_PRON захотеть_VERB зарабатывать_VERB наш_DET общий_ADJ дело_NOUN ради_ADP бог_NOUN сам_DET создавать_VERB ресурс_NOUN похожий_ADJ пациент_NOUN старение_NOUN плюс_NOUN отличие_NOUN открытый_ADJ база_NOUN данный_ADJ маркер_NOUN терапия_NOUN старение_NOUN принадлежать_VERB все_PRON участник_NOUN проект_NOUN детально_ADV поговорить_VERB ноябрь_NOUN ключ_NOUN начинать_VERB 12 скоро_ADV повесить_VERB анкета_NOUN запись_NOUN мероприятие_NOUN михаил_NOUN батин_NOUN пост_NOUN рамка_NOUN общественный_ADJ проект_NOUN технология_NOUN долголетие_NOUN другой_DET запись_NOUN читать_VERB тэгу_NOUN longtech технология_NOUN радикальный_ADJ продление_NOUN жизнь_NOUN человек_NOUN рассказывать_VERB научный_ADJ возможность_NOUN долгий_ADJ жизнь_NOUN путь_NOUN достижение_NOUN основной_ADJ версия_NOUN данный_ADJ паблик_NOUN располагать_VERB вконтакте_NOUN пост_NOUN транслироваться_VERB фейсбук_NOUN некоторые_PRON избранный_ADJ пост_NOUN транслироваться_VERB голос_NOUN цель_NOUN изменять_VERB отношение_NOUN общество_NOUN возможность_NOUN лечить_VERB старение_NOUN автор_NOUN хотеть_VERB доносить_VERB свой_DET мысль_NOUN максимально_ADV широкий_ADJ аудитория_NOUN поддерживать_VERB публикация_NOUN этот_DET пост_NOUN голос_NOUN возможно_ADV сам_DET прийти_VERB платформа_NOUN пока_ADV поручать_VERB транслировать_VERB запись_NOUN'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_doc = preprocess_doc(seq_list[1200])\n",
    "lemmas_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('старение_NOUN', 14),\n",
       " ('шаг_NOUN', 10),\n",
       " ('исследование_NOUN', 8),\n",
       " ('все_PRON', 8),\n",
       " ('человек_NOUN', 7),\n",
       " ('терапия_NOUN', 7),\n",
       " ('клинический_ADJ', 6),\n",
       " ('сам_DET', 5),\n",
       " ('это_PRON', 5),\n",
       " ('один_DET', 5),\n",
       " ('против_ADP', 5),\n",
       " ('вопрос_NOUN', 4),\n",
       " ('который_DET', 4),\n",
       " ('жизнь_NOUN', 4),\n",
       " ('научный_ADJ', 4),\n",
       " ('другой_DET', 4),\n",
       " ('свой_DET', 4),\n",
       " ('результат_NOUN', 4),\n",
       " ('открывать_VERB', 4),\n",
       " ('организация_NOUN', 4),\n",
       " ('пост_NOUN', 4),\n",
       " ('самый_DET', 3),\n",
       " ('принимать_VERB', 3),\n",
       " ('витамин_NOUN', 3),\n",
       " ('создавать_VERB', 3),\n",
       " ('медицинский_ADJ', 3),\n",
       " ('должный_ADJ', 3),\n",
       " ('анализ_NOUN', 3),\n",
       " ('тип_NOUN', 3),\n",
       " ('собственный_ADJ', 3),\n",
       " ('проект_NOUN', 3),\n",
       " ('голос_NOUN', 3),\n",
       " ('запись_NOUN', 3),\n",
       " ('долголетие_NOUN', 2),\n",
       " ('дело_NOUN', 2),\n",
       " ('наука_NOUN', 2),\n",
       " ('статин_NOUN', 2),\n",
       " ('далее_ADV', 2),\n",
       " ('какой_DET', 2),\n",
       " ('работать_VERB', 2),\n",
       " ('майкл_NOUN', 2),\n",
       " ('шнайдер_NOUN', 2),\n",
       " ('препарат_NOUN', 2),\n",
       " ('продление_NOUN', 2),\n",
       " ('процесс_NOUN', 2),\n",
       " ('плюс_NOUN', 2),\n",
       " ('биомаркер_NOUN', 2),\n",
       " ('скорость_NOUN', 2),\n",
       " ('нужно_ADV', 2),\n",
       " ('распространение_NOUN', 2)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "fd = FreqDist(nltk.word_tokenize(lemmas_doc))\n",
    "fd.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = codecs.open('datasets/golos_io_topics-res-lines.csv', encoding='utf-8', mode='w+')\n",
    "for item in seq_list:\n",
    "    if item is not None:\n",
    "        lemmas_doc = preprocess_doc(item)\n",
    "        print(lemmas_doc, file=fout, sep=\"\\n\")\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"люди употребляют различные препараты делятся своими впечатлениями . акцент ноотропы , продление жизни . всему этому процессу хватает организованности . собственно этим займемся . прекрасный план . шаг 1. личный медицинский кабинет . должны результаты ваших анализов . сдавали . терапии , которые осуществляли . самое важно , должны результаты диагностики старения . плюс , , описание интервенций против старения . биомаркеры скорости старения далеки совершенств\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'analysis': [{'lex': 'человек', 'gr': 'S,муж,од=им,мн'}], 'text': 'люди'}, {'text': ' '}, {'analysis': [{'lex': 'употреблять', 'gr': 'V,пе=непрош,мн,изъяв,3-л,несов'}], 'text': 'употребляют'}, {'text': ' '}, {'analysis': [{'lex': 'различный', 'gr': 'A=(вин,мн,полн,неод|им,мн,полн)'}], 'text': 'различные'}, {'text': ' '}, {'analysis': [{'lex': 'препарат', 'gr': 'S,муж,неод=(вин,мн|им,мн)'}], 'text': 'препараты'}, {'text': ' '}, {'analysis': [{'lex': 'делиться', 'gr': 'V,несов,нп=непрош,мн,изъяв,3-л'}], 'text': 'делятся'}, {'text': ' '}, {'analysis': [{'lex': 'свой', 'gr': 'APRO=твор,мн'}], 'text': 'своими'}, {'text': ' '}, {'analysis': [{'lex': 'впечатление', 'gr': 'S,сред,неод=твор,мн'}], 'text': 'впечатлениями'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'акцент', 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'акцент'}, {'text': ' '}, {'analysis': [{'lex': 'ноотроп', 'qual': 'bastard', 'gr': 'S,муж,неод=(вин,мн|им,мн)'}], 'text': 'ноотропы'}, {'text': ' , '}, {'analysis': [{'lex': 'продление', 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'продление'}, {'text': ' '}, {'analysis': [{'lex': 'жизнь', 'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}], 'text': 'жизни'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'весь', 'gr': 'APRO=(дат,ед,муж|дат,ед,сред)'}], 'text': 'всему'}, {'text': ' '}, {'analysis': [{'lex': 'этот', 'gr': 'APRO=(дат,ед,муж|дат,ед,сред)'}], 'text': 'этому'}, {'text': ' '}, {'analysis': [{'lex': 'процесс', 'gr': 'S,муж,неод=дат,ед'}], 'text': 'процессу'}, {'text': ' '}, {'analysis': [{'lex': 'хватать', 'gr': 'V,несов=(непрош,ед,изъяв,3-л|непрош,изъяв)'}], 'text': 'хватает'}, {'text': ' '}, {'analysis': [{'lex': 'организованность', 'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}], 'text': 'организованности'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'собственно', 'gr': 'ADV,вводн='}], 'text': 'собственно'}, {'text': ' '}, {'analysis': [{'lex': 'этот', 'gr': 'APRO=(дат,мн|твор,ед,муж|твор,ед,сред)'}], 'text': 'этим'}, {'text': ' '}, {'analysis': [{'lex': 'заниматься', 'gr': 'V,нп=(мн,пов,1-л,сов|непрош,мн,изъяв,1-л,сов)'}], 'text': 'займемся'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'прекрасный', 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'прекрасный'}, {'text': ' '}, {'analysis': [{'lex': 'план', 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'план'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'шаг', 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'шаг'}, {'text': ' '}, {'text': '1'}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'личный', 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'личный'}, {'text': ' '}, {'analysis': [{'lex': 'медицинский', 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'медицинский'}, {'text': ' '}, {'analysis': [{'lex': 'кабинет', 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'кабинет'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'должный', 'gr': 'A=мн,кр'}], 'text': 'должны'}, {'text': ' '}, {'analysis': [{'lex': 'результат', 'gr': 'S,муж,неод=(вин,мн|им,мн)'}], 'text': 'результаты'}, {'text': ' '}, {'analysis': [{'lex': 'ваш', 'gr': 'APRO=(пр,мн|род,мн|вин,мн,од)'}], 'text': 'ваших'}, {'text': ' '}, {'analysis': [{'lex': 'анализ', 'gr': 'S,муж,неод=род,мн'}], 'text': 'анализов'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'сдавать', 'gr': 'V,пе=прош,мн,изъяв,несов'}], 'text': 'сдавали'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'терапия', 'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}], 'text': 'терапии'}, {'text': ' , '}, {'analysis': [{'lex': 'который', 'gr': 'APRO=(им,мн|вин,мн,неод)'}], 'text': 'которые'}, {'text': ' '}, {'analysis': [{'lex': 'осуществлять', 'gr': 'V,пе=прош,мн,изъяв,несов'}], 'text': 'осуществляли'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'самый', 'gr': 'APRO=(вин,ед,сред|им,ед,сред)'}], 'text': 'самое'}, {'text': ' '}, {'analysis': [{'lex': 'важно', 'gr': 'ADV='}], 'text': 'важно'}, {'text': ' , '}, {'analysis': [{'lex': 'должный', 'gr': 'A=мн,кр'}], 'text': 'должны'}, {'text': ' '}, {'analysis': [{'lex': 'результат', 'gr': 'S,муж,неод=(вин,мн|им,мн)'}], 'text': 'результаты'}, {'text': ' '}, {'analysis': [{'lex': 'диагностика', 'gr': 'S,жен,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'диагностики'}, {'text': ' '}, {'analysis': [{'lex': 'старение', 'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'старения'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'плюс', 'gr': 'CONJ='}], 'text': 'плюс'}, {'text': ' , , '}, {'analysis': [{'lex': 'описание', 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'описание'}, {'text': ' '}, {'analysis': [{'lex': 'интервенция', 'gr': 'S,жен,неод=род,мн'}], 'text': 'интервенций'}, {'text': ' '}, {'analysis': [{'lex': 'против', 'gr': 'PR='}], 'text': 'против'}, {'text': ' '}, {'analysis': [{'lex': 'старение', 'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'старения'}, {'text': ' '}, {'text': '.'}, {'text': ' '}, {'analysis': [{'lex': 'биомаркер', 'qual': 'bastard', 'gr': 'S,муж,неод=(вин,мн|им,мн)'}], 'text': 'биомаркеры'}, {'text': ' '}, {'analysis': [{'lex': 'скорость', 'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}], 'text': 'скорости'}, {'text': ' '}, {'analysis': [{'lex': 'старение', 'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'старения'}, {'text': ' '}, {'analysis': [{'lex': 'далекий', 'gr': 'A=мн,кр'}], 'text': 'далеки'}, {'text': ' '}, {'analysis': [{'lex': 'совершенство', 'gr': 'S,сред,неод=род,мн'}], 'text': 'совершенств'}, {'text': '\\n'}]\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "lemmas = m.analyze(text)\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[0]['analysis'][0]['gr'].split(\",\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
